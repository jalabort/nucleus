{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Save-model\" data-toc-modified-id=\"Save-model-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Save model</a></span></li><li><span><a href=\"#Save-architecture\" data-toc-modified-id=\"Save-architecture-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Save architecture</a></span></li><li><span><a href=\"#Save-weights\" data-toc-modified-id=\"Save-weights-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Save weights</a></span></li></ul></li><li><span><a href=\"#Inference-Model\" data-toc-modified-id=\"Inference-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Inference Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Save-model\" data-toc-modified-id=\"Save-model-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Save model</a></span></li><li><span><a href=\"#Save-architecture\" data-toc-modified-id=\"Save-architecture-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Save architecture</a></span></li><li><span><a href=\"#Save-weights\" data-toc-modified-id=\"Save-weights-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Save weights</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nucleus.detection import *\n",
    "from nucleus.detection.backbones.managers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_manager = MobileNetManager()\n",
    "backbone = backbone_manager.create_model(alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone = tf.keras.applications.MobileNet(\n",
    "#     include_top=False,\n",
    "#     weights='imagenet',\n",
    "#     input_shape=(None, None, 3)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_manager = YoloManager()\n",
    "detector = detector_manager.create_model(\n",
    "    backbone=backbone,\n",
    "    n_classes=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.summary(line_length=117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model=detector,\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    expand_nested=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_manager.save_model(\n",
    "    model=detector, \n",
    "    save_format='tf',\n",
    "    custom_objects=backbone_manager.custom_objects,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = detector_manager.load_model(\n",
    "    save_format='tf',\n",
    "    custom_objects=backbone_manager.custom_objects\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_manager.save_model_arch(model=detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = detector_manager.load_model_arch(\n",
    "    custom_objects=backbone_manager.custom_objects\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_manager.save_model_weights(model=detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = detector_manager.load_model_weights(model=detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = detector_manager.create_matcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_detector = detector_manager.create_inference_model(model=detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_detector.summary(line_length=117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model=inference_detector,\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    expand_nested=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nucleus.detection.layers import YoloInferenceLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_manager.save_model(\n",
    "    model=inference_detector,\n",
    "    save_format='tf',\n",
    "    overwrite=True,\n",
    "    custom_objects={\n",
    "        **backbone_manager.custom_objects,\n",
    "        'YoloInferenceLayer': YoloInferenceLayer\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_detector = detector_manager.load_model(\n",
    "    inference=True, \n",
    "    save_format='tf',\n",
    "    custom_objects={\n",
    "        **backbone_manager.custom_objects,\n",
    "        'YoloInferenceLayer': YoloInferenceLayer\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_manager.save_model_arch(model=inference_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_detector = detector_manager.load_model_arch(\n",
    "    inference=True, \n",
    "    custom_objects={\n",
    "        **backbone_manager.custom_objects,\n",
    "        'YoloInferenceLayer': YoloInferenceLayer\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_manager.save_model_weights(model=inference_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_detector = detector_manager.load_model_weights(model=inference_detector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
